using System;
using System.Threading.Tasks;
using System.Runtime.InteropServices;
using System.Linq;
using System.IO;
using System.Net;
using System.Net.Sockets;
using System.Threading;
using System.Collections.Concurrent;
using Microsoft.CognitiveServices.Speech;
using Microsoft.CognitiveServices.Speech.Audio;
using Microsoft.CognitiveServices.Speech.Translation;
using NAudio.CoreAudioApi;
using NAudio.Wave;
using dotenv.net;

// Classe helper para callback de PushAudioOutputStream
public class PushStreamCallback : PushAudioOutputStreamCallback
{
    private Action<byte[]> onAudioData;

    public PushStreamCallback(Action<byte[]> onAudioData)
    {
        this.onAudioData = onAudioData;
    }

    public override uint Write(byte[] dataBuffer)
    {
        onAudioData?.Invoke(dataBuffer);
        return (uint)dataBuffer.Length;
    }

    public override void Close()
    {
        // Nada a fazer
    }
}

public class Program
{
    static string selectedOutputDevice = "";
    static bool userWantsToHear = false;
    static bool otherWantsToHear = false;

    // Cache de configura√ß√µes para evitar recria√ß√£o
    static SpeechConfig? cachedSpeechConfig = null;
    static SpeechTranslationConfig? cachedTranslationConfig = null;
    static string cachedSpeechKey = "";
    static string cachedRegion = "";

    // Token para cancellation
    static CancellationTokenSource? translationCancellation = null;

    // Pool de MemoryStream para reuso (melhor performance)
    static readonly ConcurrentBag<MemoryStream> memoryStreamPool = new ConcurrentBag<MemoryStream>();

    // Cache de dispositivos de √°udio (Lazy initialization)
    static readonly Lazy<MMDeviceEnumerator> deviceEnumerator = new Lazy<MMDeviceEnumerator>(() => new MMDeviceEnumerator());

    static async Task Main(string[] args)
    {
        DotEnv.Load();
        DisplayHeader();
        SelectAudioConfiguration();
        await TestAzureSpeechConnection();
        translationCancellation = new CancellationTokenSource();
        await StartRealTimeTranslation();
    }

    static void SelectAudioConfiguration()
    {
        Console.WriteLine("‚öôÔ∏è  CONFIGURA√á√ÉO DE √ÅUDIO\n");

        // Pergunta 1: Voc√™ quer se ouvir?
        Console.WriteLine("üéß Voc√™ quer se ouvir (ouvir o √°udio traduzido)?");
        Console.WriteLine("1Ô∏è‚É£  Sim, quero ouvir");
        Console.WriteLine("2Ô∏è‚É£  N√£o, sem √°udio local\n");
        Console.Write("Digite sua op√ß√£o (1 ou 2): ");
        string option1 = Console.ReadLine();

        if (option1 == "1")
        {
            userWantsToHear = true;
            Console.WriteLine();
            SelectLocalAudioDevice();
            otherWantsToHear = false;
        }
        else
        {
            userWantsToHear = false;
            Console.WriteLine("‚úì Sem √°udio local\n");

            // Pergunta 2: Quer que a pessoa te escute? (apenas se N√ÉO quer ouvir)
            Console.WriteLine("üë• Quer que outras pessoas te escutem (via Discord/OBS)?");
            Console.WriteLine("1Ô∏è‚É£  Sim, quero compartilhar o √°udio");
            Console.WriteLine("2Ô∏è‚É£  N√£o, sem √°udio virtual\n");
            Console.Write("Digite sua op√ß√£o (1 ou 2): ");
            string option2 = Console.ReadLine();

            if (option2 == "1")
            {
                otherWantsToHear = true;
                Console.WriteLine();
                SelectVirtualAudioDevice();
            }
            else
            {
                otherWantsToHear = false;
                Console.WriteLine("‚úì Sem √°udio virtual\n");
            }
        }

        DisplayAudioConfig();
    }

    static void SelectLocalAudioDevice()
    {
        Console.WriteLine("üîä Selecione onde VOC√ä quer ouvir o √°udio traduzido:\n");

        var devices = GetAudioDevices(DataFlow.Render).Where(d => !d.Contains("CABLE")).ToList();

        if (devices.Count == 0)
        {
            Console.WriteLine("‚ùå Nenhum dispositivo local encontrado!\n");
            userWantsToHear = false;
            return;
        }

        for (int i = 0; i < devices.Count; i++)
        {
            Console.WriteLine($"{i + 1}Ô∏è‚É£  {devices[i]}");
        }

        Console.Write($"\nDigite o n√∫mero (1-{devices.Count}): ");
        string option = Console.ReadLine();

        if (int.TryParse(option, out int deviceIndex) && deviceIndex > 0 && deviceIndex <= devices.Count)
        {
            Console.WriteLine($"‚úì Voc√™ ouvir√° em: {devices[deviceIndex - 1]}\n");
        }
        else
        {
            Console.WriteLine("‚ùå Op√ß√£o inv√°lida! Usando dispositivo padr√£o...\n");
        }
    }

    static void SelectVirtualAudioDevice()
    {
        Console.WriteLine("üéôÔ∏è  Selecione por onde OUTRAS PESSOAS v√£o ouvir (via Discord/OBS):\n");

        var allDevices = GetAudioDevices(DataFlow.Render);
        Console.WriteLine("üìä Dispositivos dispon√≠veis (DEBUG):");
        foreach (var dev in allDevices)
        {
            Console.WriteLine($"  - {dev}");
        }
        Console.WriteLine();

        var devices = allDevices.Where(d => d.Contains("CABLE")).ToList();

        if (devices.Count == 0)
        {
            Console.WriteLine("‚ùå Nenhum dispositivo virtual encontrado!");
            Console.WriteLine("‚ö†Ô∏è  Instale VB-Audio Virtual Cable para compartilhar √°udio\n");
            otherWantsToHear = false;
            return;
        }

        for (int i = 0; i < devices.Count; i++)
        {
            Console.WriteLine($"{i + 1}Ô∏è‚É£  {devices[i]}");
        }

        Console.Write($"\nDigite o n√∫mero (1-{devices.Count}): ");
        string option = Console.ReadLine();

        if (int.TryParse(option, out int deviceIndex) && deviceIndex > 0 && deviceIndex <= devices.Count)
        {
            selectedOutputDevice = devices[deviceIndex - 1];
            Console.WriteLine($"‚úì Outras pessoas ouvir√£o em: {selectedOutputDevice}\n");
        }
        else
        {
            Console.WriteLine("‚ùå Op√ß√£o inv√°lida!\n");
            otherWantsToHear = false;
        }
    }

    static void DisplayAudioConfig()
    {
        Console.WriteLine(new string('=', 50));
        Console.WriteLine("üìã RESUMO DE CONFIGURA√á√ÉO");
        Console.WriteLine(new string('=', 50));
        Console.WriteLine($"üéß Voc√™ ouve: {(userWantsToHear ? "SIM" : "N√ÉO")}");
        Console.WriteLine($"üë• Outros ouvem: {(otherWantsToHear ? "SIM - " + selectedOutputDevice : "N√ÉO")}");
        Console.WriteLine(new string('=', 50) + "\n");
    }

    static async Task TestAzureSpeechConnection()
    {
        try
        {
            Console.WriteLine("üìÇ Carregando configura√ß√µes...\n");

            string speechKey = Environment.GetEnvironmentVariable("SPEECH_KEY");
            string region = Environment.GetEnvironmentVariable("SPEECH_REGION");
            string recognitionLanguage = Environment.GetEnvironmentVariable("RECOGNITION_LANGUAGE");
            string translationTargetLanguage = Environment.GetEnvironmentVariable("TRANSLATION_TARGET_LANGUAGE");
            string synthesisLanguage = Environment.GetEnvironmentVariable("SYNTHESIS_LANGUAGE");
            string voiceName = Environment.GetEnvironmentVariable("VOICE_NAME");

            if (string.IsNullOrEmpty(speechKey) || string.IsNullOrEmpty(region))
            {
                Console.WriteLine("‚ùå Erro: SPEECH_KEY ou SPEECH_REGION n√£o configurados no .env\n");
                return;
            }

            DisplayConfig(region, recognitionLanguage, translationTargetLanguage, synthesisLanguage, voiceName);

            Console.WriteLine("üîó Conectando ao Azure Speech Services...");
            var speechConfig = SpeechConfig.FromSubscription(speechKey, region);
            DisplaySuccess();
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ùå Erro na conex√£o: {ex.Message}\n");
        }
    }

    static void DisplayHeader()
    {
        Console.WriteLine("\n" + new string('=', 50));
        Console.WriteLine("   üé§ TRADU√á√ÉO EM TEMPO REAL - Azure Speech");
        Console.WriteLine(new string('=', 50) + "\n");
    }

    static void DisplayConfig(string region, string? recognitionLang, string? translationLang, string? synthesisLang, string? voiceName)
    {
        Console.WriteLine("‚úì Vari√°veis carregadas:");
        Console.WriteLine($"  ‚Ä¢ Region: {region}");
        Console.WriteLine($"  ‚Ä¢ Reconhecimento: {recognitionLang ?? "N/A"}");
        Console.WriteLine($"  ‚Ä¢ Tradu√ß√£o: {translationLang ?? "N/A"}");
        Console.WriteLine($"  ‚Ä¢ S√≠ntese: {synthesisLang ?? "N/A"}");
        Console.WriteLine($"  ‚Ä¢ Voz: {voiceName ?? "N/A"}\n");
    }

    static void DisplaySuccess()
    {
        Console.WriteLine("‚úì Conex√£o estabelecida!\n");
        Console.WriteLine(new string('=', 50));
        Console.WriteLine("‚úÖ Sistema pronto para usar!");
        Console.WriteLine(new string('=', 50) + "\n");
    }

    static async Task StartRealTimeTranslation()
    {
        Console.WriteLine("\n" + new string('=', 50));
        Console.WriteLine("üé§ INICIANDO TRADU√á√ÉO EM TEMPO REAL");
        Console.WriteLine(new string('=', 50) + "\n");

        try
        {
            string speechKey = Environment.GetEnvironmentVariable("SPEECH_KEY");
            string region = Environment.GetEnvironmentVariable("SPEECH_REGION");
            string targetLanguage = Environment.GetEnvironmentVariable("TRANSLATION_TARGET_LANGUAGE");
            string synthesisLanguage = Environment.GetEnvironmentVariable("SYNTHESIS_LANGUAGE");
            string voiceName = Environment.GetEnvironmentVariable("VOICE_NAME");

            // Usar cache de configura√ß√µes para evitar recria√ß√£o a cada loop
            var translationConfig = GetCachedTranslationConfig(speechKey, region);
            translationConfig.SpeechRecognitionLanguage = "pt-BR";
            translationConfig.AddTargetLanguage(targetLanguage ?? "en");

            using (var audioConfig = AudioConfig.FromDefaultMicrophoneInput())
            using (var recognizer = new TranslationRecognizer(translationConfig, audioConfig))
            {
                Console.WriteLine("üé§ Fale algo em portugu√™s... (pressione Ctrl+C para parar)\n");

                // Usar reconhecimento cont√≠nuo √© MUITO mais r√°pido que RecognizeOnceAsync
                recognizer.Recognizing += (s, e) =>
                {
                    if (!string.IsNullOrWhiteSpace(e.Result.Text))
                    {
                        Console.WriteLine($"üîÑ Reconhecendo: {e.Result.Text}");
                    }
                };

                recognizer.Recognized += async (s, e) =>
                {
                    if (e.Result.Reason == ResultReason.TranslatedSpeech)
                    {
                        Console.WriteLine($"‚úì Reconhecido (PT-BR): {e.Result.Text}");

                        if (e.Result.Translations.ContainsKey(targetLanguage))
                        {
                            string translatedText = e.Result.Translations[targetLanguage];
                            Console.WriteLine($"‚úì Traduzido ({targetLanguage.ToUpper()}): {translatedText}\n");

                            // Executar s√≠ntese e reprodu√ß√£o
                            await SynthesizeAndPlayAudioOptimized(speechKey, region, translatedText, synthesisLanguage, voiceName);
                        }
                    }
                    else if (e.Result.Reason == ResultReason.NoMatch)
                    {
                        Console.WriteLine("‚ö†Ô∏è  Nenhuma fala detectada\n");
                    }
                };

                recognizer.Canceled += (s, e) =>
                {
                    var cancellation = CancellationDetails.FromResult(e.Result);
                    Console.WriteLine($"‚ùå Erro: {cancellation.ErrorDetails}\n");
                };

                // INICIAR RECONHECIMENTO CONT√çNUO
                await recognizer.StartContinuousRecognitionAsync();

                // Aguardar at√© ser cancelado
                while (!translationCancellation?.Token.IsCancellationRequested ?? true)
                {
                    await Task.Delay(100);
                }

                await recognizer.StopContinuousRecognitionAsync();
            }

            Console.WriteLine("\n‚úÖ Tradu√ß√£o finalizada!");
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ùå Erro: {ex.Message}");
        }
    }

    // M√©todo auxiliar para cache de SpeechTranslationConfig
    static SpeechTranslationConfig GetCachedTranslationConfig(string speechKey, string region)
    {
        if (cachedTranslationConfig == null || cachedSpeechKey != speechKey || cachedRegion != region)
        {
            cachedTranslationConfig = SpeechTranslationConfig.FromSubscription(speechKey, region);
            cachedSpeechKey = speechKey;
            cachedRegion = region;
        }
        return cachedTranslationConfig;
    }

    // M√©todo auxiliar para cache de SpeechConfig
    static SpeechConfig GetCachedSpeechConfig(string speechKey, string region)
    {
        if (cachedSpeechConfig == null || cachedSpeechKey != speechKey || cachedRegion != region)
        {
            cachedSpeechConfig = SpeechConfig.FromSubscription(speechKey, region);
            cachedSpeechKey = speechKey;
            cachedRegion = region;
        }
        return cachedSpeechConfig;
    }

    static async Task SynthesizeAndPlayAudioOptimized(string speechKey, string region, string text, string language, string voiceName)
    {
        try
        {
            // Usar cache para SpeechConfig
            var speechConfig = GetCachedSpeechConfig(speechKey, region);
            speechConfig.SpeechSynthesisLanguage = language;
            speechConfig.SpeechSynthesisVoiceName = voiceName;

            // Se um dispositivo foi selecionado, usar MemoryStream (MAIS R√ÅPIDO que arquivo)
            if (!string.IsNullOrEmpty(selectedOutputDevice))
            {
                Console.WriteLine("üîä Sintetizando √°udio traduzido (mem√≥ria)...");

                // Pegar MemoryStream do pool ou criar novo
                if (!memoryStreamPool.TryTake(out var audioStream))
                {
                    audioStream = new MemoryStream(65536); // Pr√©-alocar 64KB para melhor performance
                }

                audioStream.Position = 0;
                audioStream.SetLength(0); // Limpar stream reutilizado

                try
                {
                    // SINTETIZAR direto em mem√≥ria usando PushAudioOutputStream com callback
                    byte[] audioData = null;
                    var pushStream = AudioOutputStream.CreatePushStream(new PushStreamCallback(audioBytes =>
                    {
                        audioStream.Write(audioBytes, 0, audioBytes.Length);
                    }));

                    using (var audioConfig = AudioConfig.FromStreamOutput(pushStream))
                    using (var synthesizer = new SpeechSynthesizer(speechConfig, audioConfig))
                    {
                        var result = await synthesizer.SpeakTextAsync(text);

                        if (result.Reason == ResultReason.SynthesizingAudioCompleted)
                        {
                            audioStream.Position = 0;
                            Console.WriteLine("‚úì √Åudio sintetizado com sucesso!");

                            // Reproduzir do stream de mem√≥ria (bem mais r√°pido!)
                            await PlayAudioFromMemoryOptimizedAsync(audioStream, selectedOutputDevice);
                        }
                        else if (result.Reason == ResultReason.Canceled)
                        {
                            var cancellation = SpeechSynthesisCancellationDetails.FromResult(result);
                            Console.WriteLine($"‚ùå Erro na s√≠ntese: {cancellation.ErrorDetails}\n");
                        }
                    }
                }
                finally
                {
                    // Devolver stream ao pool para reuso
                    memoryStreamPool.Add(audioStream);
                }
            }
            else if (userWantsToHear)
            {
                // Usar dispositivo padr√£o para o usu√°rio ouvir (mais r√°pido)
                using (var audioConfig = AudioConfig.FromDefaultSpeakerOutput())
                using (var synthesizer = new SpeechSynthesizer(speechConfig, audioConfig))
                {
                    Console.WriteLine("üîä Reproduzindo √°udio traduzido...");
                    var result = await synthesizer.SpeakTextAsync(text);

                    if (result.Reason == ResultReason.SynthesizingAudioCompleted)
                    {
                        Console.WriteLine("‚úì √Åudio reproduzido com sucesso!\n");
                    }
                    else if (result.Reason == ResultReason.Canceled)
                    {
                        var cancellation = SpeechSynthesisCancellationDetails.FromResult(result);
                        Console.WriteLine($"‚ùå Erro na s√≠ntese: {cancellation.ErrorDetails}\n");
                    }
                }
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ùå Erro ao reproduzir √°udio: {ex.Message}\n");
        }
    }

    // Vers√£o otimizada: reproduz √°udio PCM bruto diretamente da mem√≥ria
    static async Task PlayAudioFromMemoryOptimizedAsync(MemoryStream audioStream, string deviceName)
    {
        try
        {
            var enumerator = deviceEnumerator.Value;
            var devices = enumerator.EnumerateAudioEndPoints(DataFlow.Render, DeviceState.Active);
            int deviceIndex = -1;
            int currentIndex = 0;

            // Busca r√°pida do dispositivo
            foreach (var device in devices)
            {
                if (device.FriendlyName == deviceName)
                {
                    deviceIndex = currentIndex;
                    break;
                }
                currentIndex++;
            }

            if (deviceIndex == -1)
            {
                Console.WriteLine("‚ö†Ô∏è  Dispositivo n√£o encontrado.\n");
                return;
            }

            // Azure Speech entrega PCM bruto (16-bit, 16kHz, mono)
            // Usar RawSourceWaveStream para ler PCM bruto sem header RIFF
            audioStream.Position = 0;
            var waveFormat = new WaveFormat(16000, 16, 1); // 16kHz, 16-bit, mono

            using (var rawStream = new RawSourceWaveStream(audioStream, waveFormat))
            using (var waveOutEvent = new WaveOutEvent { DeviceNumber = deviceIndex })
            {
                waveOutEvent.Init(rawStream);
                waveOutEvent.Play();
                Console.WriteLine($"‚ñ∂Ô∏è  Reproduzindo em: {deviceName}");

                // Aguardar reprodu√ß√£o terminar
                while (waveOutEvent.PlaybackState == PlaybackState.Playing)
                {
                    await Task.Delay(50);
                }

                Console.WriteLine("‚úì Reprodu√ß√£o conclu√≠da!\n");
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ùå Erro ao reproduzir √°udio: {ex.Message}\n");
        }
    }

    static List<string> GetAudioDevices(DataFlow dataFlow)
    {
        var devices = new List<string>();

        try
        {
            var enumerator = new MMDeviceEnumerator();
            var audioDevices = enumerator.EnumerateAudioEndPoints(dataFlow, DeviceState.Active);

            foreach (var device in audioDevices)
            {
                devices.Add(device.FriendlyName);
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ö†Ô∏è  Erro ao enumerar dispositivos: {ex.Message}");
        }

        return devices;
    }
}